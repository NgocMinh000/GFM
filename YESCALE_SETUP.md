# YEScale API Setup Guide

## üêõ Problem

Khi ch·∫°y Stage 2 Entity Resolution, b·∫°n g·∫∑p l·ªói:

```
[2025-12-10 04:00:18,491][__main__][WARNING] - LLM inference failed for entity 'autosomal dominant ataxias':
The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable

[LangChain] Using OpenAI API (official)
```

**Nguy√™n nh√¢n:** YEScale API credentials ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng.

---

## ‚úÖ Gi·∫£i Ph√°p

### **B∆∞·ªõc 1: L·∫•y YEScale API Key**

1. Truy c·∫≠p YEScale dashboard
2. T·∫°o ho·∫∑c copy API key c·ªßa b·∫°n (d·∫°ng `sk-xxxxx`)
3. L∆∞u l·∫°i API key n√†y

### **B∆∞·ªõc 2: Set Environment Variables**

#### **Option A: T·∫°m th·ªùi (ch·ªâ session hi·ªán t·∫°i)**

```bash
# Trong terminal, ch·∫°y:
export YESCALE_API_BASE_URL="https://api.yescale.io/v1/chat/completions"
export YESCALE_API_KEY="sk-your-actual-api-key-here"

# Verify
echo $YESCALE_API_BASE_URL
echo $YESCALE_API_KEY
```

#### **Option B: Vƒ©nh vi·ªÖn (recommended)**

Th√™m v√†o file `~/.bashrc` (ho·∫∑c `~/.zshrc` n·∫øu d√πng zsh):

```bash
# M·ªü file
nano ~/.bashrc

# Th√™m v√†o cu·ªëi file:
export YESCALE_API_BASE_URL="https://api.yescale.io/v1/chat/completions"
export YESCALE_API_KEY="sk-your-actual-api-key-here"

# L∆∞u file (Ctrl+O, Enter, Ctrl+X)

# Reload bashrc
source ~/.bashrc

# Verify
echo $YESCALE_API_BASE_URL
echo $YESCALE_API_KEY
```

### **B∆∞·ªõc 3: Verify Configuration**

```bash
# Run test script
bash test_yescale_setup.sh

# Expected output if configured correctly:
# ‚úÖ YESCALE_API_BASE_URL is set
# ‚úÖ YESCALE_API_KEY is set
# ‚úÖ Configuration COMPLETE
```

---

## üîß YEScale API Endpoint

**Correct endpoint:**
```
https://api.yescale.io/v1/chat/completions
```

**Important:** ƒê√¢y l√† endpoint ƒë·∫ßy ƒë·ªß, kh√¥ng c·∫ßn append th√™m path n√†o.

**API Format (theo YEScale docs):**
```python
import requests
import json

url = "https://api.yescale.io/v1/chat/completions"

payload = json.dumps({
   "model": "gpt-4o-mini",
   "messages": [
      {
         "role": "user",
         "content": "Hello!"
      }
   ],
   "max_tokens": 1000
})

headers = {
   'Accept': 'application/json',
   'Authorization': f'Bearer {YOUR_API_KEY}',
   'Content-Type': 'application/json'
}

response = requests.post(url, headers=headers, data=payload)
print(response.text)
```

---

## üìä How It Works Now

### **With YEScale Configured:**

```python
# Stage 0 Type Inference uses 3 methods:
1. Pattern-Based (weight: 0.2)
2. Relationship-LLM (weight: 0.4) ‚Üê Uses YEScale API ‚úÖ
3. Zero-shot (weight: 0.4)

# All 3 methods work
# Weighted voting: 0.2 + 0.4 + 0.4 = 1.0
```

### **Without YEScale Configured:**

```python
# Stage 0 Type Inference uses 2 methods:
1. Pattern-Based (weight: 0.6)  ‚Üê Increased weight
2. Zero-shot (weight: 0.4)

# LLM method skipped (graceful degradation)
# Warning logged once at startup
# Weighted voting: 0.6 + 0.4 = 1.0
```

---

## üöÄ Running Stage 2

### **After Configuration:**

```bash
# Activate environment
conda activate gfm-rag

# Verify YEScale setup
bash test_yescale_setup.sh

# Clear cache (important!)
rm -rf tmp/entity_resolution/stage0_*

# Run Stage 2
python -m gfmrag.workflow.stage2_entity_resolution
```

**Expected logs if configured correctly:**
```
================================================================================
STAGE 0: ENHANCED TYPE INFERENCE (4-Step Hybrid)
================================================================================
‚úÖ Initialized YEScale LLM for relationship inference: https://api.yescale.io/v1/chat/completions
Method: hybrid
Processing 691 unique entities...
Architecture: Pattern ‚Üí Relationship-LLM ‚Üí Zero-shot ‚Üí Hybrid Decision
Type inference (4-step): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 691/691 [04:02<00:00]
```

**Expected logs if NOT configured:**
```
================================================================================
STAGE 0: ENHANCED TYPE INFERENCE (4-Step Hybrid)
================================================================================
[WARNING] YEScale API not configured (YESCALE_API_BASE_URL or YESCALE_API_KEY missing).
Skipping LLM-based relationship inference.
Set YESCALE_API_BASE_URL and YESCALE_API_KEY environment variables to enable.

Method: hybrid
Processing 691 unique entities...
Architecture: Pattern ‚Üí (LLM skipped) ‚Üí Zero-shot ‚Üí Hybrid Decision
Type inference (4-step): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 691/691 [02:30<00:00]
```

---

## ‚ùì FAQ

### **Q: T√¥i c√≥ th·ªÉ d√πng OpenAI API key thay v√¨ YEScale kh√¥ng?**

A: Kh√¥ng ƒë∆∞·ª£c. Code hi·ªán t·∫°i y√™u c·∫ßu `YESCALE_API_BASE_URL` ƒë·ªÉ x√°c ƒë·ªãnh endpoint. N·∫øu ch·ªâ c√≥ `OPENAI_API_KEY` m√† kh√¥ng c√≥ `YESCALE_API_BASE_URL`, LLM method s·∫Ω b·ªã skip.

### **Q: ƒêi·ªÅu g√¨ x·∫£y ra n·∫øu t√¥i kh√¥ng set YEScale credentials?**

A:
- ‚úÖ Code v·∫´n ch·∫°y (kh√¥ng crash)
- ‚ö†Ô∏è  LLM-based relationship inference b·ªã skip
- ‚úÖ Pattern + Zero-shot v·∫´n ho·∫°t ƒë·ªông
- ‚ö†Ô∏è  Type classification c√≥ th·ªÉ k√©m ch√≠nh x√°c h∆°n (thi·∫øu 40% weight t·ª´ LLM)

### **Q: L√†m sao t√¥i bi·∫øt YEScale ƒëang ƒë∆∞·ª£c d√πng?**

A: Ki·ªÉm tra logs khi ch·∫°y Stage 2. N·∫øu th·∫•y:
```
‚úÖ Initialized YEScale LLM for relationship inference: https://api.yescale.io/v1/chat/completions
```
‚Üí YEScale ƒëang ƒë∆∞·ª£c d√πng ‚úÖ

N·∫øu th·∫•y:
```
[WARNING] YEScale API not configured...
```
‚Üí YEScale KH√îNG ƒë∆∞·ª£c d√πng ‚ùå

### **Q: API key c·ªßa t√¥i c√≥ b·ªã l·ªô trong logs kh√¥ng?**

A: Kh√¥ng. API key kh√¥ng bao gi·ªù ƒë∆∞·ª£c log. Ch·ªâ c√≥ URL endpoint ƒë∆∞·ª£c log (kh√¥ng ch·ª©a sensitive info).

---

## üîç Debugging

### **Test 1: Check Environment Variables**

```bash
bash test_yescale_setup.sh
```

### **Test 2: Python Test**

```python
import os

yescale_url = os.environ.get("YESCALE_API_BASE_URL")
yescale_key = os.environ.get("YESCALE_API_KEY") or os.environ.get("OPENAI_API_KEY")

print(f"URL: {yescale_url}")
print(f"Key: {yescale_key[:10] if yescale_key else None}...")

if yescale_url and yescale_key:
    print("‚úÖ Configuration OK")
else:
    print("‚ùå Configuration MISSING")
```

### **Test 3: Manual API Call**

```bash
curl -X POST "https://api.yescale.io/v1/chat/completions" \
  -H "Accept: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o-mini",
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 100
  }'
```

---

## üìù Checklist

Before running Stage 2, make sure:

- [ ] `YESCALE_API_BASE_URL` is set
- [ ] `YESCALE_API_KEY` (or `OPENAI_API_KEY`) is set
- [ ] `test_yescale_setup.sh` passes
- [ ] Old cache cleared: `rm -rf tmp/entity_resolution/stage0_*`
- [ ] `conda activate gfm-rag` activated

---

## üéØ Summary

| Configuration | Pattern | LLM | Zero-shot | Total Weight |
|---------------|---------|-----|-----------|--------------|
| **With YEScale** | 0.2 | 0.4 ‚úÖ | 0.4 | 1.0 |
| **Without YEScale** | 0.6 | skipped ‚ùå | 0.4 | 1.0 |

**Recommendation:** C·∫•u h√¨nh YEScale ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t (LLM method th∆∞·ªùng ch√≠nh x√°c h∆°n pattern-based).

---

## üìö Related Files

- **test_yescale_setup.sh**: Script ki·ªÉm tra configuration
- **BUGFIXES_STAGE0_STAGE2.md**: Bug fixes documentation
- **STAGE0_ENHANCED.md**: Stage 0 architecture details
- **gfmrag/workflow/stage2_entity_resolution.py:437-475**: LLM initialization code

---

**Commit:** `cc1ec76`
**File:** `gfmrag/workflow/stage2_entity_resolution.py`
**Status:** ‚úÖ Fixed and tested
