# H∆∞·ªõng D·∫´n Chi Ti·∫øt: Ch·∫°y v√† ƒê√°nh Gi√° Stage 3 UMLS Mapping

## üìã M·ª•c L·ª•c
1. [Prerequisites - Chu·∫©n b·ªã](#1-prerequisites---chu·∫©n-b·ªã)
2. [C√†i ƒê·∫∑t Dependencies](#2-c√†i-ƒë·∫∑t-dependencies)
3. [Download UMLS Data](#3-download-umls-data)
4. [C·∫•u H√¨nh Pipeline](#4-c·∫•u-h√¨nh-pipeline)
5. [Ch·∫°y Pipeline](#5-ch·∫°y-pipeline)
6. [Xem K·∫øt Qu·∫£](#6-xem-k·∫øt-qu·∫£)
7. [ƒê√°nh Gi√° Ch·∫•t L∆∞·ª£ng](#7-ƒë√°nh-gi√°-ch·∫•t-l∆∞·ª£ng)
8. [Troubleshooting](#8-troubleshooting)

---

## 1. Prerequisites - Chu·∫©n B·ªã

### 1.1 Ki·ªÉm Tra H·ªá Th·ªëng

```bash
# Ki·ªÉm tra Python version (c·∫ßn >= 3.8)
python --version

# Ki·ªÉm tra GPU (khuy·∫øn ngh·ªã c√≥ GPU)
nvidia-smi

# Ki·ªÉm tra disk space (c·∫ßn ~50GB tr·ªëng)
df -h
```

### 1.2 D·ªØ Li·ªáu C·∫ßn C√≥

‚úÖ **B·∫Øt bu·ªôc:**
- `data/kg_clean.txt` - Knowledge Graph t·ª´ Stage 2
- UMLS files (MRCONSO.RRF, MRSTY.RRF, MRDEF.RRF)

‚úÖ **T·ª± ƒë·ªông t·∫°o:**
- Pipeline s·∫Ω t·ª± ƒë·ªông t·∫°o c√°c file cache v√† output

---

## 2. C√†i ƒê·∫∑t Dependencies

### 2.1 Core Dependencies

```bash
# C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt
pip install torch transformers faiss-cpu scikit-learn tqdm numpy

# N·∫øu c√≥ GPU, d√πng faiss-gpu thay v√¨ faiss-cpu
pip install faiss-gpu
```

### 2.2 Visualization Dependencies (T√πy ch·ªçn)

```bash
# ƒê·ªÉ t·∫°o bi·ªÉu ƒë·ªì ƒë√°nh gi√°
pip install matplotlib seaborn
```

### 2.3 Verify Installation

```bash
python -c "
import torch
import transformers
import faiss
import sklearn
print('‚úì All core dependencies installed')
"

python -c "
import matplotlib
import seaborn
print('‚úì Visualization dependencies installed')
" 2>/dev/null || echo "‚ö† Visualization libs not installed (optional)"
```

---

## 3. Download UMLS Data

### 3.1 ƒêƒÉng K√Ω UMLS License

**QUAN TR·ªåNG:** UMLS y√™u c·∫ßu license mi·ªÖn ph√≠

1. Truy c·∫≠p: https://www.nlm.nih.gov/research/umls/
2. T·∫°o t√†i kho·∫£n UTS (UMLS Terminology Services)
3. Ch·∫•p nh·∫≠n License Agreement
4. Download UMLS Metathesaurus

### 3.2 Download Full Release

```bash
# T·∫°o th∆∞ m·ª•c UMLS
mkdir -p data/umls

# Download UMLS 2024AB (ho·∫∑c version m·ªõi nh·∫•t)
# Sau khi login v√†o UTS, download file ZIP:
# - umls-2024AB-full.zip (~10GB)

# Gi·∫£i n√©n
cd data/umls
unzip umls-2024AB-full.zip
cd 2024AB/META
```

### 3.3 Verify UMLS Files

```bash
# Ki·ªÉm tra c√°c file c·∫ßn thi·∫øt
ls -lh data/umls/2024AB/META/

# Ph·∫£i c√≥ 3 files n√†y:
# MRCONSO.RRF (~15GB)  - Concept names v√† synonyms
# MRSTY.RRF   (~500MB) - Semantic types
# MRDEF.RRF   (~300MB) - Definitions
```

**N·∫øu kh√¥ng c√≥ UMLS License:**
C√≥ th·ªÉ d√πng UMLS subset nh·ªè h∆°n cho testing (kh√¥ng khuy·∫øn ngh·ªã cho production):
```bash
# Download UMLS Sample (kh√¥ng c·∫ßn license, ch·ªâ cho test)
# https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/release/sample.html
```

---

## 4. C·∫•u H√¨nh Pipeline

### 4.1 Ki·ªÉm Tra File Input

```bash
# Verify KG file t·ªìn t·∫°i
ls -lh data/kg_clean.txt

# Xem v√†i d√≤ng ƒë·∫ßu
head -20 data/kg_clean.txt

# ƒê·∫øm s·ªë entities
wc -l data/kg_clean.txt
```

### 4.2 T·∫°o Config File (T√πy ch·ªçn)

Pipeline c√≥ config m·∫∑c ƒë·ªãnh t·ªët, nh∆∞ng b·∫°n c√≥ th·ªÉ t√πy ch·ªânh:

```bash
# T·∫°o file config t√πy ch·ªânh
cat > config/my_umls_config.yaml << 'EOF'
# Input paths
kg_clean_path: "./data/kg_clean.txt"
umls_data_dir: "./data/umls/2024AB/META"
output_root: "./tmp/umls_mapping"

# UMLS files
mrconso_path: "./data/umls/2024AB/META/MRCONSO.RRF"
mrsty_path: "./data/umls/2024AB/META/MRSTY.RRF"
mrdef_path: "./data/umls/2024AB/META/MRDEF.RRF"

# Stage 2: Candidate Generation
sapbert_model: "cambridgeltl/SapBERT-from-PubMedBERT-fulltext"
sapbert_batch_size: 256  # Gi·∫£m n·∫øu GPU memory th·∫•p
sapbert_top_k: 64
ensemble_final_k: 128

# Stage 3: Cluster Aggregation
cluster_output_k: 64

# Stage 4: Hard Negative Filtering
hard_neg_similarity_threshold: 0.7
hard_neg_output_k: 32

# Stage 5: Cross-Encoder
cross_encoder_model: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"

# Stage 6: Confidence
confidence_high_threshold: 0.75
propagation_min_agreement: 0.8

# Runtime
device: "cuda"  # ho·∫∑c "cpu" n·∫øu kh√¥ng c√≥ GPU
num_processes: 10
force_recompute: false
save_intermediate: true
EOF
```

### 4.3 Config Parameters Quan Tr·ªçng

| Parameter | M√¥ t·∫£ | Gi√° tr·ªã khuy·∫øn ngh·ªã |
|-----------|-------|---------------------|
| `sapbert_batch_size` | Batch size cho encoding | GPU: 256-512, CPU: 32-64 |
| `ensemble_final_k` | S·ªë candidates sau ensemble | 128 (c√¢n b·∫±ng recall/precision) |
| `confidence_high_threshold` | Ng∆∞·ª°ng high confidence | 0.75 (60%+ mappings s·∫Ω high) |
| `device` | GPU ho·∫∑c CPU | "cuda" n·∫øu c√≥ GPU |
| `save_intermediate` | L∆∞u k·∫øt qu·∫£ trung gian | true (ƒë·ªÉ debug) |

---

## 5. Ch·∫°y Pipeline

### 5.1 Ch·∫°y To√†n B·ªô Pipeline (Khuy·∫øn Ngh·ªã)

```bash
# C√°ch 1: D√πng config m·∫∑c ƒë·ªãnh
python run_umls_pipeline.py

# C√°ch 2: D√πng custom config
python run_umls_pipeline.py --config config/my_umls_config.yaml

# C√°ch 3: Override specific params
python run_umls_pipeline.py \
    --umls-dir data/umls/2024AB/META \
    --kg-file data/kg_clean.txt \
    --output-dir tmp/umls_mapping
```

### 5.2 Ch·∫°y T·ª´ng Stage Ri√™ng L·∫ª

**Stage 0: Load UMLS (ch·ªâ ch·∫°y 1 l·∫ßn)**
```bash
python run_umls_pipeline.py --stages stage0_umls_loading
```

**Stage 1: Preprocessing**
```bash
python run_umls_pipeline.py --stages stage1_preprocessing
```

**Stage 2 Setup: SapBERT + TF-IDF (ch·ªâ ch·∫°y 1 l·∫ßn, m·∫•t 2-3 gi·ªù)**
```bash
python run_umls_pipeline.py --stages stage2_setup_sapbert stage2_setup_tfidf
```

**Stage 2-6: Main Pipeline**
```bash
python run_umls_pipeline.py --stages \
    stage2_candidate_generation \
    stage3_cluster_aggregation \
    stage4_hard_negative_filtering \
    stage5_cross_encoder_reranking \
    stage6_final_output
```

### 5.3 Monitor Progress

**Terminal 1: Ch·∫°y pipeline**
```bash
python run_umls_pipeline.py
```

**Terminal 2: Theo d√µi logs**
```bash
# Xem logs real-time
tail -f tmp/umls_mapping/pipeline.log

# Ho·∫∑c d√πng watch ƒë·ªÉ refresh
watch -n 5 'tail -30 tmp/umls_mapping/pipeline.log'
```

**Terminal 3: Check status**
```bash
# Ki·ªÉm tra status t·ª´ng 30s
watch -n 30 'python run_umls_pipeline.py --status'
```

### 5.4 Resume N·∫øu B·ªã Gi√°n ƒêo·∫°n

```bash
# N·∫øu pipeline b·ªã d·ª´ng gi·ªØa ch·ª´ng, resume t·ª´ checkpoint
python run_umls_pipeline.py --resume
```

### 5.5 Force Rerun Specific Stage

```bash
# Ch·∫°y l·∫°i stage c·ª• th·ªÉ (b·ªè qua cache)
python run_umls_pipeline.py \
    --stages stage3_cluster_aggregation \
    --force
```

---

## 6. Xem K·∫øt Qu·∫£

### 6.1 Output Directory Structure

```
tmp/umls_mapping/
‚îú‚îÄ‚îÄ final_umls_mappings.json          # ‚≠ê FILE CH√çNH - K·∫øt qu·∫£ mapping
‚îú‚îÄ‚îÄ umls_mapping_triples.txt          # Format KG triples
‚îú‚îÄ‚îÄ mapping_statistics.json           # Th·ªëng k√™ t·ªïng quan
‚îú‚îÄ‚îÄ manual_review_queue.json          # Mappings c·∫ßn review th·ªß c√¥ng
‚îú‚îÄ‚îÄ pipeline_metrics.json             # Metrics chi ti·∫øt
‚îú‚îÄ‚îÄ pipeline_report.txt               # B√°o c√°o vƒÉn b·∫£n
‚îÇ
‚îú‚îÄ‚îÄ visualizations/                   # üìä Bi·ªÉu ƒë·ªì ƒë√°nh gi√°
‚îÇ   ‚îú‚îÄ‚îÄ candidate_reduction_funnel.png
‚îÇ   ‚îú‚îÄ‚îÄ confidence_distribution.png
‚îÇ   ‚îú‚îÄ‚îÄ score_progression.png
‚îÇ   ‚îú‚îÄ‚îÄ stage_timing.png
‚îÇ   ‚îú‚îÄ‚îÄ cluster_statistics.png
‚îÇ   ‚îú‚îÄ‚îÄ metric_heatmap.png
‚îÇ   ‚îú‚îÄ‚îÄ quality_metrics.png
‚îÇ   ‚îî‚îÄ‚îÄ visualization_summary.txt
‚îÇ
‚îú‚îÄ‚îÄ stage31_preprocessing/            # K·∫øt qu·∫£ Stage 1
‚îÇ   ‚îú‚îÄ‚îÄ entities.txt
‚îÇ   ‚îú‚îÄ‚îÄ synonym_clusters.json
‚îÇ   ‚îî‚îÄ‚îÄ normalized_entities.json
‚îÇ
‚îú‚îÄ‚îÄ stage32_candidates.json           # K·∫øt qu·∫£ Stage 2 (128 candidates)
‚îú‚îÄ‚îÄ stage33_aggregated.json           # K·∫øt qu·∫£ Stage 3 (64 candidates)
‚îú‚îÄ‚îÄ stage34_filtered.json             # K·∫øt qu·∫£ Stage 4 (32 candidates)
‚îú‚îÄ‚îÄ stage35_reranked.json             # K·∫øt qu·∫£ Stage 5 (reranked)
‚îÇ
‚îî‚îÄ‚îÄ cache/                            # Cache files (c√≥ th·ªÉ x√≥a ƒë·ªÉ ch·∫°y l·∫°i)
    ‚îú‚îÄ‚îÄ umls_concepts.pkl
    ‚îú‚îÄ‚îÄ umls_embeddings.pkl
    ‚îî‚îÄ‚îÄ umls_faiss.index
```

### 6.2 Xem File K·∫øt Qu·∫£ Ch√≠nh

**A. Final Mappings (JSON format)**
```bash
# Xem structure
head -50 tmp/umls_mapping/final_umls_mappings.json

# ƒê·∫øm s·ªë mappings
jq 'length' tmp/umls_mapping/final_umls_mappings.json

# Xem 1 mapping example
jq 'to_entries | first' tmp/umls_mapping/final_umls_mappings.json
```

**Format c·ªßa final_umls_mappings.json:**
```json
{
  "diabetes": {
    "cui": "C0020538",
    "name": "Diabetes Mellitus",
    "confidence": 0.89,
    "tier": "high",
    "alternatives": [
      {"cui": "C0011847", "name": "Diabetes", "score": 0.85},
      {"cui": "C0011849", "name": "Diabetes Mellitus, Insulin-Dependent", "score": 0.78}
    ],
    "cluster_size": 3,
    "is_propagated": false,
    "confidence_factors": {
      "score_margin": 0.42,
      "absolute_score": 0.89,
      "cluster_consensus": 0.85,
      "method_agreement": 0.80
    }
  }
}
```

**B. Mapping Statistics**
```bash
# Xem th·ªëng k√™ t·ªïng quan
cat tmp/umls_mapping/mapping_statistics.json | jq .
```

**Output:**
```json
{
  "total_entities": 5000,
  "high_confidence": 3200,
  "medium_confidence": 1300,
  "low_confidence": 500,
  "propagated": 800,
  "high_confidence_pct": "64.00%",
  "medium_confidence_pct": "26.00%",
  "low_confidence_pct": "10.00%",
  "propagated_pct": "16.00%"
}
```

**C. KG Triples Format**
```bash
# Xem triples ƒë·ªÉ th√™m v√†o KG
head -20 tmp/umls_mapping/umls_mapping_triples.txt

# Format: entity | mapped_to_cui | CUI
# Example:
# diabetes | mapped_to_cui | C0020538
# hypertension | mapped_to_cui | C0020538
```

### 6.3 Xem Bi·ªÉu ƒê·ªì ƒê√°nh Gi√°

```bash
# M·ªü th∆∞ m·ª•c visualizations
cd tmp/umls_mapping/visualizations

# List t·∫•t c·∫£ plots
ls -lh *.png

# M·ªü plots (macOS)
open *.png

# M·ªü plots (Linux v·ªõi image viewer)
eog *.png
# ho·∫∑c
xdg-open *.png

# M·ªü plots (Windows)
start *.png
```

**7 Bi·ªÉu ƒê·ªì ƒê∆∞·ª£c T·∫°o:**

1. **candidate_reduction_funnel.png** - Funnel chart t·ª´ 128‚Üí64‚Üí32‚Üí1 candidates
2. **confidence_distribution.png** - Pie + bar charts ph√¢n b·ªë confidence tiers
3. **score_progression.png** - Line chart ƒëi·ªÉm s·ªë qua c√°c stages
4. **stage_timing.png** - Bar chart th·ªùi gian ch·∫°y t·ª´ng stage
5. **cluster_statistics.png** - Th·ªëng k√™ cluster sizes
6. **metric_heatmap.png** - Heatmap t·∫•t c·∫£ metrics
7. **quality_metrics.png** - Dashboard so s√°nh actual vs target

### 6.4 ƒê·ªçc Pipeline Report

```bash
# ƒê·ªçc b√°o c√°o vƒÉn b·∫£n
cat tmp/umls_mapping/pipeline_report.txt

# Ho·∫∑c d√πng less ƒë·ªÉ scroll
less tmp/umls_mapping/pipeline_report.txt
```

**Report bao g·ªìm:**
- Overall summary (th·ªùi gian, warnings, errors)
- Chi ti·∫øt t·ª´ng stage (duration, input/output, metrics)
- Warnings v√† errors (n·∫øu c√≥)

---

## 7. ƒê√°nh Gi√° Ch·∫•t L∆∞·ª£ng

### 7.1 Metrics Quan Tr·ªçng

**A. Confidence Distribution (Metric ch√≠nh)**

```bash
# Xem confidence distribution
jq '.high_confidence_pct, .medium_confidence_pct, .low_confidence_pct' \
   tmp/umls_mapping/mapping_statistics.json
```

**‚úÖ Target Quality:**
- **High Confidence ‚â• 60%** (t·ªët nh·∫•t)
- **Medium Confidence: 20-30%**
- **Low Confidence < 20%**

**V√≠ d·ª• k·∫øt qu·∫£ t·ªët:**
```
High:   64%  ‚úì (target: >60%)
Medium: 26%  ‚úì (target: 20-30%)
Low:    10%  ‚úì (target: <20%)
```

**B. Average Confidence**

```bash
# T√≠nh average confidence
jq '[.[] | .confidence] | add / length' \
   tmp/umls_mapping/final_umls_mappings.json
```

**‚úÖ Target:** Average confidence > 0.65

**C. Score Margin (Gap gi·ªØa top-1 v√† top-2)**

```bash
# Xem score margin trong metrics
jq '.stages[] | select(.stage_name | contains("Stage 3.6")) | .metrics.avg_score_margin' \
   tmp/umls_mapping/pipeline_metrics.json
```

**‚úÖ Target:** Average score margin > 0.20 (clear winner)

**D. Propagation Rate**

```bash
# Xem t·ª∑ l·ªá propagated mappings
jq '.propagated_pct' tmp/umls_mapping/mapping_statistics.json
```

**‚úÖ Target:** 10-30% (synonym clusters ƒë∆∞·ª£c leverage t·ªët)

### 7.2 Quality Checks

**A. Check Low Confidence Mappings**

```bash
# Xem c√°c mappings c√≥ confidence th·∫•p
jq 'to_entries | map(select(.value.tier == "low")) | length' \
   tmp/umls_mapping/final_umls_mappings.json

# List 10 low confidence mappings
jq 'to_entries | map(select(.value.tier == "low")) | .[0:10]' \
   tmp/umls_mapping/final_umls_mappings.json
```

**B. Check Manual Review Queue**

```bash
# S·ªë l∆∞·ª£ng c·∫ßn review th·ªß c√¥ng
jq 'length' tmp/umls_mapping/manual_review_queue.json

# Xem 5 cases ƒë·∫ßu ti√™n
jq 'to_entries | .[0:5]' tmp/umls_mapping/manual_review_queue.json
```

**C. Check Warnings**

```bash
# Xem warnings t·ª´ pipeline
jq '.stages[] | select(.warnings | length > 0) | {stage: .stage_name, warnings: .warnings}' \
   tmp/umls_mapping/pipeline_metrics.json
```

**D. Spot Check Random Samples**

```bash
# Random sample 10 mappings ƒë·ªÉ verify th·ªß c√¥ng
jq 'to_entries | map(select(.value.tier == "high")) | .[0:10] | .[] | {entity: .key, cui: .value.cui, name: .value.name, confidence: .value.confidence}' \
   tmp/umls_mapping/final_umls_mappings.json
```

### 7.3 Validation v·ªõi Gold Standard (N·∫øu c√≥)

N·∫øu b·∫°n c√≥ gold standard annotations:

```python
import json

# Load predictions
with open('tmp/umls_mapping/final_umls_mappings.json') as f:
    predictions = json.load(f)

# Load gold standard
with open('gold_standard.json') as f:
    gold = json.load(f)

# T√≠nh accuracy
correct = 0
total = 0
for entity, gold_cui in gold.items():
    if entity in predictions:
        pred_cui = predictions[entity]['cui']
        if pred_cui == gold_cui:
            correct += 1
        total += 1

accuracy = correct / total
print(f"Accuracy: {accuracy:.2%}")
print(f"Correct: {correct}/{total}")
```

### 7.4 Error Analysis

**A. Entities Without Candidates**

```bash
# T√¨m entities kh√¥ng t√¨m ƒë∆∞·ª£c CUI n√†o
grep "No candidates found for:" tmp/umls_mapping/pipeline.log | wc -l
```

**B. Cluster Disagreement**

```bash
# T√¨m clusters c√≥ outliers
grep "outlier" tmp/umls_mapping/pipeline.log | head -20
```

**C. Hard Negatives**

```bash
# Xem hard negative penalties
jq '.stages[] | select(.stage_name | contains("Stage 3.4")) | .metrics.candidates_with_penalties' \
   tmp/umls_mapping/pipeline_metrics.json
```

---

## 8. Troubleshooting

### 8.1 Pipeline Fails

**L·ªói: CUDA Out of Memory**
```bash
# Solution 1: Gi·∫£m batch size
python run_umls_pipeline.py --batch-size 128

# Solution 2: D√πng CPU
python run_umls_pipeline.py --device cpu

# Solution 3: T·∫Øt FP16
python run_umls_pipeline.py --no-amp
```

**L·ªói: UMLS files not found**
```bash
# Ki·ªÉm tra paths
ls -la data/umls/2024AB/META/MRCONSO.RRF

# Fix: Ch·ªâ ƒë·ªãnh ƒë√∫ng path
python run_umls_pipeline.py --umls-dir /ƒë√∫ng/path/to/umls/META
```

**L·ªói: Pipeline stopped gi·ªØa ch·ª´ng**
```bash
# Resume t·ª´ checkpoint
python run_umls_pipeline.py --resume

# N·∫øu kh√¥ng work, reset v√† ch·∫°y l·∫°i
python run_umls_pipeline.py --reset --force
```

### 8.2 Low Quality Results

**High Confidence < 60%**

Nguy√™n nh√¢n c√≥ th·ªÉ:
1. UMLS data kh√¥ng match domain c·ªßa b·∫°n
2. Entity normalization qu√° aggressive
3. Threshold qu√° cao

Solutions:
```bash
# 1. Gi·∫£m confidence threshold
# Edit config: confidence_high_threshold: 0.65 (t·ª´ 0.75)

# 2. Ki·ªÉm tra preprocessing
head -100 tmp/umls_mapping/stage31_preprocessing/normalized_entities.json

# 3. TƒÉng s·ªë candidates
# Edit config: ensemble_final_k: 256 (t·ª´ 128)
```

**Nhi·ªÅu Low Confidence Mappings**

```bash
# 1. Check Stage 2 candidate quality
jq '.stages[] | select(.stage_name | contains("Stage 3.2")) | .metrics.avg_top1_score' \
   tmp/umls_mapping/pipeline_metrics.json

# N·∫øu avg_top1_score < 0.6 ‚Üí v·∫•n ƒë·ªÅ ·ªü candidate generation

# 2. Tune parameters
# TƒÉng sapbert_top_k v√† tfidf_top_k trong config
```

### 8.3 Performance Issues

**Stage 2 Setup qu√° ch·∫≠m (>5 gi·ªù)**

```bash
# 1. Verify GPU ƒë∆∞·ª£c s·ª≠ d·ª•ng
nvidia-smi

# 2. TƒÉng batch size n·∫øu GPU c√≤n memory
python run_umls_pipeline.py --batch-size 512

# 3. Enable multi-GPU
python run_umls_pipeline.py --no-multi-gpu false
```

**Disk Space ƒê·∫ßy**

```bash
# Ki·ªÉm tra space
df -h tmp/umls_mapping/

# X√≥a cache kh√¥ng c·∫ßn thi·∫øt (sau khi ƒë√£ c√≥ results)
rm -rf tmp/umls_mapping/cache/*.pkl

# X√≥a intermediate files
rm tmp/umls_mapping/stage3*.json
```

### 8.4 Debug Mode

```bash
# Ch·∫°y v·ªõi debug logging
export LOG_LEVEL=DEBUG
python run_umls_pipeline.py

# Ho·∫∑c ch·ªâ ch·∫°y Stage 2 v·ªõi sample nh·ªè ƒë·ªÉ test
# Edit kg_clean.txt ƒë·ªÉ ch·ªâ c√≥ 100 entities ƒë·∫ßu
head -100 data/kg_clean.txt > data/kg_clean_sample.txt
python run_umls_pipeline.py --kg-file data/kg_clean_sample.txt
```

---

## 9. Tips & Best Practices

### 9.1 L·∫ßn ƒê·∫ßu Ch·∫°y

```bash
# 1. Test v·ªõi sample nh·ªè tr∆∞·ªõc
head -500 data/kg_clean.txt > data/kg_clean_sample.txt
python run_umls_pipeline.py --kg-file data/kg_clean_sample.txt

# 2. Ki·ªÉm tra k·∫øt qu·∫£ sample
cat tmp/umls_mapping/mapping_statistics.json

# 3. N·∫øu OK, ch·∫°y full dataset
python run_umls_pipeline.py
```

### 9.2 Optimize Performance

```bash
# GPU settings (n·∫øu c√≥ GPU m·∫°nh)
python run_umls_pipeline.py \
    --batch-size 512 \
    --device cuda

# CPU settings (n·∫øu kh√¥ng c√≥ GPU)
python run_umls_pipeline.py \
    --batch-size 64 \
    --device cpu \
    --num-workers 8
```

### 9.3 Monitoring Long Runs

```bash
# Script ƒë·ªÉ monitor v√† alert
#!/bin/bash
# monitor_pipeline.sh

while true; do
    STATUS=$(python run_umls_pipeline.py --status 2>&1 | grep "completed")
    echo "[$(date)] $STATUS"

    # Check n·∫øu done
    if echo "$STATUS" | grep -q "6/6 stages completed"; then
        echo "‚úì Pipeline DONE!"
        # Send notification (optional)
        # mail -s "Pipeline Done" you@email.com <<< "Pipeline completed"
        break
    fi

    sleep 300  # Check m·ªói 5 ph√∫t
done
```

### 9.4 Backup Results

```bash
# Backup k·∫øt qu·∫£ quan tr·ªçng
tar -czf umls_mapping_results_$(date +%Y%m%d).tar.gz \
    tmp/umls_mapping/final_umls_mappings.json \
    tmp/umls_mapping/mapping_statistics.json \
    tmp/umls_mapping/visualizations/ \
    tmp/umls_mapping/pipeline_report.txt

# Upload to cloud (optional)
# aws s3 cp umls_mapping_results_*.tar.gz s3://your-bucket/
```

---

## 10. Quick Reference

### Commands Cheat Sheet

```bash
# Ch·∫°y to√†n b·ªô
python run_umls_pipeline.py

# Ch·∫°y v·ªõi custom config
python run_umls_pipeline.py --config config/my_config.yaml

# Resume
python run_umls_pipeline.py --resume

# Check status
python run_umls_pipeline.py --status

# Reset
python run_umls_pipeline.py --reset

# Force rerun
python run_umls_pipeline.py --force

# Specific stages
python run_umls_pipeline.py --stages stage2_candidate_generation

# Monitor logs
tail -f tmp/umls_mapping/pipeline.log

# View results
jq . tmp/umls_mapping/mapping_statistics.json
```

### File Locations

```
Input:  data/kg_clean.txt
        data/umls/2024AB/META/*.RRF

Output: tmp/umls_mapping/final_umls_mappings.json
        tmp/umls_mapping/visualizations/*.png

Logs:   tmp/umls_mapping/pipeline.log
        tmp/umls_mapping/pipeline_report.txt
```

### Quality Targets

```
‚úì High Confidence:      ‚â• 60%
‚úì Low Confidence:       < 20%
‚úì Avg Confidence:       > 0.65
‚úì Avg Score Margin:     > 0.20
‚úì Propagation Rate:     10-30%
```

---

## 11. Li√™n H·ªá & T√†i Li·ªáu

**Documentation:**
- `STAGE3_UMLS_MAPPING_ANALYSIS.md` - Ph√¢n t√≠ch chi ti·∫øt workflow
- `docs/STAGE3_METRICS_GUIDE.md` - H∆∞·ªõng d·∫´n metrics
- `docs/UMLS_MAPPING_PIPELINE.md` - Pipeline documentation

**UMLS Resources:**
- UMLS Home: https://www.nlm.nih.gov/research/umls/
- UMLS Download: https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html
- UMLS Documentation: https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/

**Papers:**
- SapBERT: https://arxiv.org/abs/2010.11784
- PubMedBERT: https://arxiv.org/abs/2007.15779

---

**Good luck! üöÄ**

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, h√£y:
1. Check logs: `tmp/umls_mapping/pipeline.log`
2. Check status: `python run_umls_pipeline.py --status`
3. Xem troubleshooting section ·ªü tr√™n
