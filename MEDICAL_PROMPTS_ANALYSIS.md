# B√ÅO C√ÅO PH√ÇN T√çCH PROMPTS - H·ªÜ TH·ªêNG GFM-RAG

## üìã M·ª§C L·ª§C
1. [T·ªïng quan](#t·ªïng-quan)
2. [Prompts cho NER (Named Entity Recognition)](#1-prompts-cho-ner)
3. [Prompts cho OpenIE (Open Information Extraction)](#2-prompts-cho-openie)
4. [Prompts cho QA (Question Answering)](#3-prompts-cho-qa)
5. [ƒê·ªÅ xu·∫•t customize cho domain Y t·∫ø](#4-ƒë·ªÅ-xu·∫•t-customize-cho-domain-y-t·∫ø)

---

## T·ªîNG QUAN

H·ªá th·ªëng GFM-RAG s·ª≠ d·ª•ng LLMs (YEScale API) cho 3 t√°c v·ª• ch√≠nh:
1. **NER**: Nh·∫≠n d·∫°ng c√°c th·ª±c th·ªÉ c√≥ t√™n trong text
2. **OpenIE**: Tr√≠ch xu·∫•t quan h·ªá gi·ªØa c√°c th·ª±c th·ªÉ (triples: subject-predicate-object)
3. **QA**: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n documents ƒë∆∞·ª£c retrieve

T·∫•t c·∫£ c√°c prompts ƒë·ªÅu s·ª≠ d·ª•ng **Few-shot learning** (cung c·∫•p examples) ƒë·ªÉ h∆∞·ªõng d·∫´n LLM.

---

## 1. PROMPTS CHO NER (Named Entity Recognition)

### üìç V·ªä TR√ç FILES:

#### File 1: `gfmrag/kg_construction/openie_extraction_instructions.py`
**D√≤ng 70-100**

```python
ner_instruction = """Your task is to extract named entities from the given paragraph.
Respond with a JSON list of entities.
Strictly follow the required JSON format.
"""

# V√≠ d·ª• m·∫´u
one_shot_passage = """Radio City
Radio City is India's first private FM radio station and was started on 3 July 2001.
It plays Hindi, English and regional songs.
Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features."""

one_shot_passage_entities = """{"named_entities":
    ["Radio City", "India", "3 July 2001", "Hindi", "English", "May 2008", "PlanetRadiocity.com"]
}
"""
```

**ƒê·∫∑c ƒëi·ªÉm:**
- ‚úÖ Domain-agnostic (kh√¥ng specific cho domain n√†o)
- ‚úÖ Few-shot v·ªõi 1 example
- ‚úÖ Output: JSON format
- ‚ö†Ô∏è Example v·ªÅ radio station (kh√¥ng li√™n quan y t·∫ø)

---

#### File 2: `gfmrag/kg_construction/ner_model/llm_ner_model.py`
**D√≤ng 33-47**

```python
query_prompt_one_shot_input = """Please extract all named entities that are important for solving the questions below.
Place the named entities in json format.

Question: Which magazine was started first Arthur's Magazine or First for Women?
"""

query_prompt_one_shot_output = """
{"named_entities": ["First for Women", "Arthur's Magazine"]}
"""

query_prompt_template = """
Question: {}
"""
```

**ƒê·∫∑c ƒëi·ªÉm:**
- ‚úÖ T·∫≠p trung v√†o entities quan tr·ªçng cho c√¢u h·ªèi
- ‚úÖ Few-shot v·ªõi 1 example
- ‚ö†Ô∏è Example v·ªÅ magazines (kh√¥ng li√™n quan y t·∫ø)
- ‚ÑπÔ∏è ƒê∆∞·ª£c d√πng cho QA-based NER

---

## 2. PROMPTS CHO OPENIE (Open Information Extraction)

### üìç V·ªä TR√ç FILE: `gfmrag/kg_construction/openie_extraction_instructions.py`
**D√≤ng 105-174**

```python
openie_post_ner_instruction = """Your task is to construct an RDF (Resource Description Framework) graph from the given passages and named entity lists.
Respond with a JSON list of triples, with each triple representing a relationship in the RDF graph.

Pay attention to the following requirements:
- Each triple should contain at least one, but preferably two, of the named entities in the list for each passage.
- Clearly resolve pronouns to their specific names to maintain clarity.
"""

# V√≠ d·ª• output
one_shot_passage_triples = """{"triples": [
            ["Radio City", "located in", "India"],
            ["Radio City", "is", "private FM radio station"],
            ["Radio City", "started on", "3 July 2001"],
            ["Radio City", "plays songs in", "Hindi"],
            ["Radio City", "plays songs in", "English"]
            ["Radio City", "forayed into", "New Media"],
            ["Radio City", "launched", "PlanetRadiocity.com"],
            ["PlanetRadiocity.com", "launched in", "May 2008"],
            ["PlanetRadiocity.com", "is", "music portal"],
            ["PlanetRadiocity.com", "offers", "news"],
            ["PlanetRadiocity.com", "offers", "videos"],
            ["PlanetRadiocity.com", "offers", "songs"]
    ]
}
"""
```

**ƒê·∫∑c ƒëi·ªÉm:**
- ‚úÖ Y√™u c·∫ßu r√µ r√†ng v·ªÅ RDF graph construction
- ‚úÖ H∆∞·ªõng d·∫´n gi·∫£i quy·∫øt ƒë·∫°i t·ª´ (pronoun resolution)
- ‚úÖ Y√™u c·∫ßu triple ch·ª©a √≠t nh·∫•t 1-2 named entities
- ‚ö†Ô∏è Example v·ªÅ radio station (kh√¥ng li√™n quan y t·∫ø)
- ‚ö†Ô∏è Relations trong example: "located in", "is", "started on", "plays songs in", "launched", "offers"

---

## 3. PROMPTS CHO QA (Question Answering)

### üìç V·ªä TR√ç FILES:

#### File 1: `gfmrag/workflow/config/qa_prompt/zero_shot.yaml`

```yaml
system_prompt: 'As an advanced reading comprehension assistant, your task is to analyze the questions and then answer them. Your response start after "Thought: ", where you will methodically break down the reasoning process, illustrating how you arrive at conclusions. Conclude with "Answer: " to present a concise, definitive response, devoid of additional elaborations.'

doc_prompt: "Wikipedia Title: {title}\n{content}\n"

question_prompt: "Question: {question}\nThought: "

examples: []
```

**ƒê·∫∑c ƒëi·ªÉm:**
- ‚úÖ Y√™u c·∫ßu reasoning process (Thought:)
- ‚úÖ Concise answer
- ‚ö†Ô∏è Gi·∫£ ƒë·ªãnh documents t·ª´ Wikipedia
- ‚ö†Ô∏è Kh√¥ng c√≥ examples (zero-shot)

---

#### File 2: `gfmrag/workflow/config/qa_prompt/hotpotqa.yaml`

```yaml
system_prompt: 'As an advanced reading comprehension assistant, your task is to analyze text passages and corresponding questions meticulously. Your response start after "Thought: ", where you will methodically break down the reasoning process, illustrating how you arrive at conclusions. Conclude with "Answer: " to present a concise, definitive response, devoid of additional elaborations.'

doc_prompt: "Wikipedia Title: {title}\n{content}\n"

question_prompt: "Question: {question}\nThought: "

examples:
  - input: |-
      Wikipedia Title: Milk and Honey (album)
      [... John Lennon album information ...]

      Wikipedia Title: Walls and Bridges
      [... John Lennon album information ...]

      Question: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records...?

    response: |-
      The album issued by Apple Records... is Walls and Bridges.
      Answer: Walls and Bridges.
```

**ƒê·∫∑c ƒëi·ªÉm:**
- ‚úÖ Few-shot v·ªõi examples
- ‚úÖ Multi-hop reasoning (c·∫ßn k·∫øt h·ª£p nhi·ªÅu documents)
- ‚ö†Ô∏è Examples v·ªÅ John Lennon/music (kh√¥ng li√™n quan y t·∫ø)
- ‚ö†Ô∏è Gi·∫£ ƒë·ªãnh Wikipedia format

---

## 4. ƒê·ªÄ XU·∫§T CUSTOMIZE CHO DOMAIN Y T·∫æ

### üè• A. PROMPTS NER CHO Y T·∫æ

#### ƒê·ªÅ xu·∫•t thay ƒë·ªïi `openie_extraction_instructions.py`:

```python
# CURRENT (Generic)
ner_instruction = """Your task is to extract named entities from the given paragraph.
Respond with a JSON list of entities.
Strictly follow the required JSON format.
"""

# PROPOSED (Medical Domain)
ner_instruction = """Your task is to extract medical named entities from the given clinical text or medical document.
Focus on extracting:
- Diseases, conditions, and symptoms
- Medications and treatments
- Medical procedures and tests
- Anatomical structures
- Patient demographics (age, gender)
- Medical devices and equipment
- Laboratory values and measurements

Respond with a JSON list of entities.
Strictly follow the required JSON format.
"""

# Example passage (Medical)
one_shot_passage = """Patient Case Report
A 45-year-old male patient presented to the emergency department with acute chest pain radiating to the left arm.
The patient has a history of hypertension and type 2 diabetes mellitus, currently managed with Metformin 1000mg twice daily and Lisinopril 10mg once daily.
ECG showed ST-segment elevation in leads II, III, and aVF, suggesting inferior wall myocardial infarction.
Troponin I levels were elevated at 5.2 ng/mL (normal <0.04 ng/mL).
Emergency coronary angiography was performed, revealing 90% stenosis of the right coronary artery."""

one_shot_passage_entities = """{"named_entities": [
    "45-year-old male",
    "acute chest pain",
    "left arm",
    "hypertension",
    "type 2 diabetes mellitus",
    "Metformin",
    "1000mg",
    "Lisinopril",
    "10mg",
    "ECG",
    "ST-segment elevation",
    "inferior wall myocardial infarction",
    "Troponin I",
    "5.2 ng/mL",
    "coronary angiography",
    "right coronary artery",
    "90% stenosis"
]}
"""
```

---

### üè• B. PROMPTS OPENIE CHO Y T·∫æ

#### ƒê·ªÅ xu·∫•t thay ƒë·ªïi cho `openie_post_ner_instruction`:

```python
# CURRENT (Generic)
openie_post_ner_instruction = """Your task is to construct an RDF (Resource Description Framework) graph from the given passages and named entity lists.
Respond with a JSON list of triples, with each triple representing a relationship in the RDF graph.

Pay attention to the following requirements:
- Each triple should contain at least one, but preferably two, of the named entities in the list for each passage.
- Clearly resolve pronouns to their specific names to maintain clarity.
"""

# PROPOSED (Medical Domain)
openie_post_ner_instruction = """Your task is to construct a medical knowledge graph from the given clinical text and named entity lists.
Extract relationships representing medical facts, such as:
- Patient characteristics: ["patient", "has", "disease/condition"]
- Treatments: ["patient", "treated with", "medication/procedure"]
- Diagnostic findings: ["test", "shows", "finding"]
- Dosage information: ["medication", "prescribed at", "dose"]
- Anatomical relationships: ["disease", "affects", "anatomical structure"]
- Temporal relationships: ["symptom", "occurred before", "diagnosis"]
- Causal relationships: ["condition", "caused by", "factor"]

Respond with a JSON list of triples, with each triple representing a medical relationship.

Pay attention to the following requirements:
- Each triple should contain at least one, but preferably two, of the medical entities in the list.
- Use clinically accurate predicates (e.g., "diagnosed with", "treated with", "indicates")
- Clearly resolve pronouns to specific patient or medical terms.
- Maintain temporal accuracy when extracting time-related relationships.
"""

# Example triples (Medical)
one_shot_passage_triples = """{"triples": [
    ["45-year-old male patient", "presented with", "acute chest pain"],
    ["acute chest pain", "radiates to", "left arm"],
    ["patient", "has medical history of", "hypertension"],
    ["patient", "has medical history of", "type 2 diabetes mellitus"],
    ["patient", "treated with", "Metformin"],
    ["Metformin", "prescribed at", "1000mg twice daily"],
    ["patient", "treated with", "Lisinopril"],
    ["Lisinopril", "prescribed at", "10mg once daily"],
    ["ECG", "showed", "ST-segment elevation"],
    ["ST-segment elevation", "indicates", "inferior wall myocardial infarction"],
    ["Troponin I", "elevated at", "5.2 ng/mL"],
    ["patient", "underwent", "coronary angiography"],
    ["coronary angiography", "revealed", "90% stenosis"],
    ["stenosis", "located in", "right coronary artery"]
]}
"""
```

---

### üè• C. PROMPTS QA CHO Y T·∫æ

#### ƒê·ªÅ xu·∫•t thay ƒë·ªïi `qa_prompt/zero_shot.yaml`:

```yaml
# PROPOSED (Medical Domain)
system_prompt: 'As an advanced medical knowledge assistant, your task is to analyze clinical documents, research papers, and medical literature to answer medical questions accurately. Your response should start after "Thought: ", where you will:
1. Identify relevant medical entities and concepts
2. Analyze relationships between symptoms, diagnoses, treatments
3. Consider clinical context and medical evidence
4. Provide reasoning based on medical knowledge

Conclude with "Answer: " to present a concise, evidence-based medical response. Always cite specific information from the provided documents.'

doc_prompt: "Medical Document: {title}\n{content}\n"

question_prompt: "Medical Question: {question}\nThought: "

examples: []
```

#### ƒê·ªÅ xu·∫•t example cho `qa_prompt/medical.yaml`:

```yaml
system_prompt: 'As an advanced medical knowledge assistant...'

doc_prompt: "Medical Document: {title}\n{content}\n"

question_prompt: "Medical Question: {question}\nThought: "

examples:
  - input: |-
      Medical Document: Diabetes Mellitus Management Guidelines
      Type 2 diabetes mellitus is a chronic metabolic disorder characterized by hyperglycemia resulting from insulin resistance and relative insulin deficiency. First-line pharmacological treatment typically includes Metformin, which reduces hepatic glucose production and improves insulin sensitivity. The standard initial dose is 500-850mg once or twice daily, titrated up to a maximum of 2000-2550mg per day. Common side effects include gastrointestinal disturbances such as nausea and diarrhea.

      Medical Document: Cardiovascular Risk in Diabetes
      Patients with type 2 diabetes have a 2-4 fold increased risk of cardiovascular disease compared to the general population. Hypertension is present in approximately 70% of diabetic patients. ACE inhibitors like Lisinopril are recommended as first-line antihypertensive agents in diabetic patients due to their nephroprotective effects. Typical starting dose is 10mg once daily, which can be increased to 40mg daily if needed.

      Medical Question: What are the first-line medications for managing a patient with type 2 diabetes and hypertension, and what are their typical starting doses?
      Thought:

    response: |-
      Based on the provided documents:
      1. For type 2 diabetes: Metformin is the first-line treatment, with starting dose of 500-850mg once or twice daily
      2. For hypertension in diabetic patients: ACE inhibitors like Lisinopril are first-line, with starting dose of 10mg once daily
      3. These medications address both conditions while providing additional benefits (Metformin improves insulin sensitivity, Lisinopril offers nephroprotection)

      Answer: First-line medications are Metformin (500-850mg once or twice daily) for diabetes and Lisinopril (10mg once daily) for hypertension. These are recommended specifically for diabetic patients with hypertension.
```

---

## 5. T·∫¨P TRUNG C√ÅC FILE C·∫¶N S·ª¨A

### ‚ö†Ô∏è PRIORITY 1 - CORE PROMPTS (B·∫ÆT BU·ªòC S·ª¨A):

1. **`gfmrag/kg_construction/openie_extraction_instructions.py`**
   - D√≤ng 70-74: `ner_instruction`
   - D√≤ng 54-64: `one_shot_passage` v√† `one_shot_passage_entities` (NER example)
   - D√≤ng 128-139: `openie_post_ner_instruction`
   - D√≤ng 110-125: `one_shot_passage_triples` (OpenIE example)

2. **`gfmrag/kg_construction/ner_model/llm_ner_model.py`**
   - D√≤ng 33-42: `query_prompt_one_shot_input` v√† `query_prompt_one_shot_output`

### ‚ö†Ô∏è PRIORITY 2 - QA PROMPTS (N√äN S·ª¨A):

3. **`gfmrag/workflow/config/qa_prompt/zero_shot.yaml`**
   - D√≤ng 1: `system_prompt`
   - D√≤ng 2: `doc_prompt`

4. **`gfmrag/workflow/config/qa_prompt/hotpotqa.yaml`**
   - D√≤ng 1: `system_prompt`
   - D√≤ng 2: `doc_prompt`
   - D√≤ng 5-25: `examples` (thay b·∫±ng medical examples)

### üìù OPTIONAL - T·∫†O FILE M·ªöI:

5. **`gfmrag/workflow/config/qa_prompt/medical.yaml`** (T·∫†O M·ªöI)
   - Copy t·ª´ `hotpotqa.yaml`
   - Customize v·ªõi medical examples

---

## 6. H∆Ø·ªöNG D·∫™N CUSTOMIZE

### B∆∞·ªõc 1: Backup files g·ªëc
```bash
cd /home/user/GFM
cp gfmrag/kg_construction/openie_extraction_instructions.py gfmrag/kg_construction/openie_extraction_instructions.py.bak
cp gfmrag/kg_construction/ner_model/llm_ner_model.py gfmrag/kg_construction/ner_model/llm_ner_model.py.bak
```

### B∆∞·ªõc 2: S·ª≠a NER prompts
- M·ªü `openie_extraction_instructions.py`
- Thay th·∫ø `ner_instruction` b·∫±ng medical version
- Thay th·∫ø `one_shot_passage` b·∫±ng medical case report
- Thay th·∫ø `one_shot_passage_entities` v·ªõi medical entities

### B∆∞·ªõc 3: S·ª≠a OpenIE prompts
- Trong c√πng file `openie_extraction_instructions.py`
- Thay th·∫ø `openie_post_ner_instruction` b·∫±ng medical version
- Thay th·∫ø `one_shot_passage_triples` v·ªõi medical triples

### B∆∞·ªõc 4: S·ª≠a QA prompts
- M·ªü `gfmrag/workflow/config/qa_prompt/zero_shot.yaml`
- Customize `system_prompt` v√† `doc_prompt`
- T·∫°o `medical.yaml` v·ªõi medical examples

### B∆∞·ªõc 5: Test
```bash
python test_yescale_connection.py  # Verify API works
python -m gfmrag.workflow.stage1_index_dataset  # Test with medical data
```

---

## 7. L∆ØU √ù QUAN TR·ªåNG

### ‚úÖ DO:
- Gi·ªØ nguy√™n JSON format output
- Gi·ªØ nguy√™n structure c·ªßa prompts (System -> Example -> User)
- S·ª≠ d·ª•ng medical terminology ch√≠nh x√°c
- Examples ph·∫£i realistic v√† clinically accurate
- Test v·ªõi medical dataset th·∫≠t

### ‚ùå DON'T:
- Kh√¥ng thay ƒë·ªïi variable names
- Kh√¥ng thay ƒë·ªïi format c·ªßa one_shot variables
- Kh√¥ng x√≥a docstrings
- Kh√¥ng break JSON syntax trong examples
- Kh√¥ng s·ª≠ d·ª•ng abbreviations kh√¥ng gi·∫£i th√≠ch

---

## 8. CHECKLIST

- [ ] Backup files g·ªëc
- [ ] ƒê·ªçc v√† hi·ªÉu current prompts
- [ ] Chu·∫©n b·ªã medical examples (real case reports)
- [ ] S·ª≠a NER instruction trong `openie_extraction_instructions.py`
- [ ] S·ª≠a NER examples trong `openie_extraction_instructions.py`
- [ ] S·ª≠a OpenIE instruction trong `openie_extraction_instructions.py`
- [ ] S·ª≠a OpenIE examples trong `openie_extraction_instructions.py`
- [ ] S·ª≠a NER query prompts trong `llm_ner_model.py`
- [ ] S·ª≠a QA system prompts trong `zero_shot.yaml`
- [ ] T·∫°o `medical.yaml` v·ªõi medical QA examples
- [ ] Test API connection
- [ ] Test stage1 pipeline v·ªõi medical data
- [ ] Verify output quality
- [ ] Document changes

---

## 9. CONTACT & SUPPORT

N·∫øu c·∫ßn h·ªó tr·ª£ khi customize prompts:
- Test YEScale API: `python test_yescale_connection.py`
- Test stage1 pipeline: `python -m gfmrag.workflow.stage1_index_dataset`
- Check logs: `gfmrag/workflow/outputs/kg_construction/*/stage1_index_dataset.log`

---

**Generated:** 2025-11-25
**System:** GFM-RAG with YEScale LLM Integration
**Purpose:** Medical Domain Customization Guide
